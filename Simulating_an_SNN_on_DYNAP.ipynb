{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWk9Yxg4awHb"
   },
   "source": [
    "# Simulating a Spiking Neural Network on DYNAP-SE\n",
    "\n",
    "Developed by [Yigit Demirag](https://www.ini.uzh.ch/fw1/modules/ini/ini.php/people/yigit) and [Giacomo Indiveri](https://www.ini.uzh.ch/fw1/modules/ini/ini.php/people/giacomo). Adapted and extended for the course [D7064E](https://www.ltu.se/edu/course/D70/D7064E/D7064E-Neuromorf-informationsbehandling-1.225526?l=en) by Fredrik Sandin.\n",
    "\n",
    "In this exercise you will simulate the silicon neuron and synapse circuits of a neuromorphic processor named DYNAP-SE1, shown in the figure below. Specifically, you will first see how a Differential Pair Integrator (DPI) silicon circuit is used in Dynap-SE1 to implement the fundamental dynamics of synapses and Adaptive Exponential Integrate-and-Fire (AdEx) neurons. The AdEx model of neurons is described in Chapters 5 and 6 in the Neuronal Dynamics [book](https://neuronaldynamics.epfl.ch/online/Pt2.html). Then you will learn how to set up neuron and synapse parameters, form networks of spiking neurons, and monitor the electrical signals at various stages in the chip. Finally, you will investigate the adaptive behavior of the neurons.\n",
    "\n",
    "![DYNAP-SE1](figures/dynap-se1.jpg)\n",
    "\n",
    "Depending on your background knowledge you may or may not be able to figure out (with reasonable effort) how the synapse and neuron circuits function. Do not feel discouraged if underlying aspects of the hardware simulation are difficult to understand. After all, how much do you know about the inner workings of a modern CPU or GPU, and the transistor circuits actually used to implement the logic gates? As programmers and engineers we can anyway be productive by understanding such things at some level of abstraction. Few know the details well. Similarly, for neuromorphic hardware we must establish and learn abstract concepts that are useful for system design and engineering purposes.\n",
    "\n",
    "This exercise will enable you to familiarize with some unique features of **dynamic** neuromorphic processors, abstractions that are key to understanding what Neuromorphic Computing is about and how it is different from Digital Computing. There is plenty of room for deepening your knowledge of the DYNAP-SE1 and dynamic neuromorphic processors by studying the references provided below and in the associated lectures.\n",
    "\n",
    "The original version of this notebook was shared at the NICE 2021 workshop and can be obtained [here](https://code.ini.uzh.ch/yigit/NICE-workshop-2021.git).\n",
    "\n",
    "## Examination\n",
    "\n",
    "There are several tasks below involving investigations that require visualisation and modification of parameter values. Read the associated text carefully and do your best to understand how/why the modifications done provide the expected result (with the time given for this exercise). When you are done you should sign up for explaining your solutions to a teacher according to the instruction in Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eavt7F5iawHd"
   },
   "source": [
    "\n",
    "## Part 1: Simulation of neuron and synapse circuits\n",
    "---\n",
    "\n",
    "#### Differential Pair Integrator (DPI)\n",
    "\n",
    "The computational principles of the brain are vastly different from conventional computers. Rather than using Boolean logic, clocked operation, and distinct memory and processing units, the biological brain works at massively parallel, fault-tolerant, asynchronous manner.\n",
    "\n",
    "In neuromorphic engineering, we aim to design compact, energy-efficient computational devices that directly _emulate_ the style of computation of the brain with **the physics of the silicon.** To achieve that, we use analog Complementary Metal-Oxide-Semiconductor (CMOS) technology to implement neural and synaptic circuits and integrate into Very Large Scale Integration (VLSI) devices. In these architectures, time represents itself (no clock) - neurons process the incoming spikes as they arrive and produce output spikes in real-time. Consequently, to process real-world sensory signals efficiently, neuromorphic systems use circuits with biologically plausible time constants that match environment statistics ($\\sim 10-100$ ms). \n",
    "\n",
    "The DPI circuit shown below is the fundamental building block used to implement silicon neurons and synapses with tunable time-constants (for details see the paper by Chicca et al referenced below).\n",
    "\n",
    "![DPI circuit](figures/DPI_advanced.png)\n",
    "\n",
    "It is totally fine if you do not understand how this circuit works. The essence is that it has the response dynamics, i.e., the relation of input current $I_{i n}$ and output current $I_{out}$ of\n",
    "\n",
    "$$\\tau \\frac{d}{d t} I_{o u t}+I_{o u t}=\\frac{I_{g}}{I_{\\tau}} I_{i n},$$\n",
    "\n",
    "where $\\tau \\triangleq C U_{T} / \\kappa I_{\\tau}$ ($C$ the capacitor, $U_T$ thermal voltage, $\\kappa$ subthreshold slope factor). The DPI circuit can be tuned by adjusting the time constant by $I_{\\tau}$ and the gain factor by $I_{g}$. Thus, the DPI circuit is simply a current-mode low pass filter with adjustable gain and time-constant. This is the building block of silicon neurons and synapses in the DYNAP-SE1.\n",
    "\n",
    "#### Silicon Neuron\n",
    "\n",
    "![Neuron circuit](figures/neuron.png)\n",
    "\n",
    "The above schematic shows the neuron circuit implementing Adaptive Exponential Integrate & Fire (AdEx) on Dynap-SE1. AdEx neurons are introduced by [Brette and Gerstner, 2005](https://www.readcube.com/library/a457847f-fdff-4d66-a32a-b3830a010b34:72216f6a-1527-440d-b775-be66fa7085a1) that capable of describing known neuronal firing patterns, e.g., adapting, bursting, delayed spike initiation, initial bursting, fast-spiking, and regular spiking. We will not go into detail of circuit analysis but describe the functional blocks. The yellow block is the input DPI circuit modeling neuron's leak conductance. The green block implements an additional low-pass ï¬lter that integrates the spikes and produces a slow current $I_{ahp}$ responsible for spike-frequency adaptation. The red block is a spike event generation amplifier implementing current-based positive feedback (modeling both $Na^{+}$ activation and inactivation conductances) and produces address-events at extremely low-power operation. Lastly, the blue block resets the neuron and keeps it in a resting state for a refractory period, set by the $V_{ref}$ bias voltage. Under some assumptions, the response dynamics of neuron block is:\n",
    "\n",
    "$$\\tau \\frac{d}{d t} I_{m e m}+I_{m e m} \\approx I_{i n}-I_{a h p}+f\\left(I_{m e m}\\right)$$\n",
    "$$\\tau_{a h p} \\frac{d}{d t} I_{a h p}+I_{a h p} \\approx I_{a h p} \\delta\\left(t_{s p i k e}\\right)$$\n",
    "\n",
    "\n",
    "Here, $I_{m e m}$ is the sub-threshold current that represents the real neuron's membrane potential variable, $I_{i n}$ is the input current that enters the neuron, $I_{a h p}$ characterizes the spike adaptation effect, $\\tau$ is the time-constant of leakage current. $f(x)$ is an exponential function with positive exponent which characterizes the passive properties, i.e. $f(x) = \\alpha e^{ \\beta x - \\gamma} + \\delta$.\n",
    "\n",
    "#### Silicon Synapse\n",
    "\n",
    "![Synapse circuit](figures/synapse.png)\n",
    "\n",
    "Lastly, the above schematic shows a typical silicon synapse circuit implemented on Dynap-SE1. The green block implements short-term depression (STD). The yellow block implements basic DPI dynamics and can be tuned to implement short-term facilitation (STF). The red block implements NMDA voltage-gated channels, and the blue block implements conductance-based voltage dependence. The simplified version of the response dynamics of the synaptic block is:\n",
    "\n",
    "$$\\tau \\frac{d}{d t} I_{s y n}(t)+I_{s y n}(t)=I_{w} \\delta\\left(t_{p r e}\\right)$$\n",
    "where $I_{s y n}$ is the synaptic current, $I_{w}$ is the gain factor (weight) of the synapse, and $\\tau$ is time constant of current decay.\n",
    "\n",
    "For more detailed explanations of neural and synaptic circuits (and especially the derivations and the assumptions behind the formulas mentioned) you can check [PDF available on arXiv.](https://arxiv.org/pdf/1403.6428.pdf)\n",
    "\n",
    ">Chicca, E., Stefanini, F., Bartolozzi, C., Indiveri, G. (2014). [Neuromorphic Electronic Circuits for Building Autonomous Cognitive Systems](https://doi.org/10.1109/JPROC.2014.2313954), Proceedings of the IEEE  102(9), 1367-1388.\n",
    "\n",
    "### Setting up the network\n",
    "\n",
    "We will use [Brian2](https://brian2.readthedocs.io/en/stable/) to implement our spiking neural network. There are other options available (NEST, PyTorch, etc.), but Brian2 is both fast and flexible when working with spikes. More importantly, the group who developed DYNAP-SE1 has already modeled the neural and synaptic circuits that the processor implements using Brian2. Thus, it is straightforward to model DYNAP-SE1 in Brian2 and simulate spiking neural networks as if they would be running on an actual processor. Super cool :)\n",
    "\n",
    "So, let's start with importing Brian2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Pifg1tcawHm"
   },
   "outputs": [],
   "source": [
    "from brian2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmSBfJ4UawHn"
   },
   "source": [
    "Brian2 allows us to write models for neuron and synapses,  create large populations of neurons, and connect them arbitrarily. On the other hand, the real chip has predefined resources, and circuits are fixed. There is no time-multiplexing of resources. Hence for this session, we created a simple `DynapSE.py` wrapper class that implements DPI neuron and synaptic circuit models and  monitors chip resources (e.g., number of available neurons per core, number of synapses between neurons, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yLRRsTVawHn"
   },
   "outputs": [],
   "source": [
    "from DynapSE import DynapSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chpJdmsWawHo"
   },
   "source": [
    "We then import dynamical array processing (Numpy) and plotting (Matplotlib) libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__O8V4K1awHo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display plots inside Jupyter cell\n",
    "%matplotlib inline \n",
    "# Set the dots-per-inch resolution of the images\n",
    "mpl.rcParams['figure.dpi'] = 90  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Te737GBAawHo"
   },
   "source": [
    "The ordinary differential equations defining neuron and synapse models should be accessible by Brian2. Let's import the DYNAP-SE1 model equations and their parameters. Also define some Brian2 settings and optionally enable compilation of the differential equations for faster execution if you have installed a compatible C++ compiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXZqRzNEawHo"
   },
   "outputs": [],
   "source": [
    "# Import the DYNAP-SE1 equations describing DPI synapses and AdEx neurons\n",
    "from equations.dynapse_eq import *\n",
    "\n",
    "# Import default parameter settings for DYNAP-SE1\n",
    "from parameters.dynapse_param import *\n",
    "\n",
    "# Ignore Brian2 base warnings\n",
    "BrianLogger.suppress_name('base')\n",
    "\n",
    "# The clock of Brian2 simulation for numerically solve ODEs\n",
    "defaultclock.dt = 20 * us\n",
    "\n",
    "# Optionally enable C++ code generation for faster spiking network simulation.\n",
    "# Requires a compiler, e.g., Visual Studio.\n",
    "# set_device('cpp_standalone', build_on_run=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPbTTMkWawHp"
   },
   "source": [
    "### Generating Input Spike Pattern\n",
    "\n",
    "The language of neuromorphic chips is spike trains. Whether we want to process the analog or digital signal, we need to convert it to spikes first. Inside Dynap-SE1, we have such converters, following a single protocol: AER (Address-Event Representation). AER uses (spike source address, timing) pair to define a single spike. In this exercise, we will not use AER but the Dirac delta function $\\rho(t)=\\sum_{i=1}^{k} \\delta\\left(t-t_{i}\\right)$ to define spike trains. \n",
    "\n",
    "In the cell below, you will see three different spike train implementations \n",
    "`regular`, `poisson`, and `cosine`. You can change the variables in the TODO section (optional) and customize your input pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWng004vawHp"
   },
   "outputs": [],
   "source": [
    "# Input Generator\n",
    "##################\n",
    "# TODO: \n",
    "# - Play with different input spike patterns by changing input_type (optional).\n",
    "#\n",
    "# Parameters\n",
    "input_type   = 'poisson' # 'regular', 'poisson' or 'cosine' (Default: poisson)\n",
    "pulse_start  = 0         # second - Start time of input (Default: 0)\n",
    "pulse_stop   = 5         # second - Stop time of input (Default: 5)\n",
    "inp_duration = 5         # second - Simulation duration (Default: 5)\n",
    "rate         = 100       # Hz or rad/sec - Spiking rate (Default: 80 Hz for regular, 100 Hz for poission, 2 rad/sec for cosine) \n",
    "##################\n",
    "\n",
    "if input_type == 'regular':\n",
    "    \n",
    "    spikes = np.zeros(inp_duration*1000)\n",
    "    dt = int(1000/rate)\n",
    "    spikes[pulse_start*1000:pulse_stop*1000:dt] = 1.0\n",
    "\n",
    "if input_type == 'poisson':\n",
    "\n",
    "    prob = rate * 1e-3\n",
    "    mask = np.random.rand(inp_duration*1000)\n",
    "    spikes = np.zeros(inp_duration*1000)\n",
    "    spikes[mask < prob] = 1.0\n",
    "    spikes[:pulse_start*1000]=0\n",
    "    spikes[pulse_stop*1000:]=0\n",
    "\n",
    "if input_type == 'cosine':\n",
    "    \n",
    "    spikes = np.zeros(inp_duration*1000)\n",
    "    time = np.linspace(0, inp_duration, inp_duration*1000)\n",
    "    co = np.cos(2 * np.pi * rate * time)\n",
    "    mask = 20 * np.random.rand(inp_duration*1000)\n",
    "    spikes[mask < co] = 1.0\n",
    "    spikes[:pulse_start*1000]=0\n",
    "    spikes[pulse_stop*1000:]=0\n",
    "\n",
    "plt.plot(spikes,'k|')\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Neuron ID\")\n",
    "plt.ylim(0.5, 1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXQ3qicEawHp"
   },
   "source": [
    "Now that we have an input spike pattern, we need to tell Brian2 to use the spikes we just generated. To do that, we define two arrays specifying spike indices (ID of spike source) and the spike timing. The sizes of two arrays match since Brian2 will check both and assign spike timings to spike sources. We will have single source ID because we generated only one spike pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2Lr4sH4awHp"
   },
   "outputs": [],
   "source": [
    "# Reinitialize the device\n",
    "device.reinit()\n",
    "device.activate()\n",
    "defaultclock.dt = 20 * us\n",
    "\n",
    "spike_timing = np.where(spikes==1)[0] * ms # Timing of spikes\n",
    "neuron_indices = np.zeros(len(spike_timing)) # ID of spike sources\n",
    "input_spike_generator = SpikeGeneratorGroup(1, indices=neuron_indices, times=spike_timing, name='InpSpikeGenerator')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_iO4cVb9awHq"
   },
   "source": [
    "### Creating a Network \n",
    "\n",
    "To create a spiking neural network on Brian2, there are three pillars we need to understand. Brian2 requires the `Network()` instance, which handles the running of the simulation.  It contains a set of Brian objects (e.g., neurons, synapses, monitors, etc.) added with `add()` function. The final `run()` method runs the simulation. \n",
    "\n",
    "After creating a `network` instance, we will pass it to the `DynapSE()` method to create a  new `chip` instance. Creating a spiking neural network and passing it to a neuromorphic chip class may seem peculiar. However, this will allow us to make sure that the chip can support the Brian2 network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPYs0269awHq"
   },
   "outputs": [],
   "source": [
    "network = Network() # Instantiate a Brian2 Network\n",
    "chip = DynapSE(network) # Instantiate a Dynap-SE1 chip implementing neural and synaptic silicon dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlDg8m89awHq"
   },
   "source": [
    "\n",
    "Now let's look at the inside of the Dynap-SE1 chip. Inside, there are four event-based, mixed-signal neuromorphic cores; each one has 256 DPI neurons. More specifically, the chip implements a generalized integrate and fire model, which unlike the LIF model does not have an explicit threshold condition for spike generation. What is the condition for spike generation? In which chapter of the Neuronal Dynamics course book is the neuron model implemented in the DYNAP-SE explained mathematically?\n",
    "\n",
    "Each neuron is identical to the others by design; however, it may have slightly different parameters due to the noise and mismatch in analog circuits. In the simulation, you can allocate `num_n` neurons from a core `X` by using `get_neurons(num_n, 'Core_X')` method, which returns a [SubGroup](https://brian2.readthedocs.io/en/stable/reference/brian2.groups.subgroup.Subgroup.html) of DPI neurons.\n",
    "\n",
    "An individual neuron can have a fan-in of 64 and a fan-out of 4k connections. Users can determine the types of the synapses to exhibit one of 4 different behaviors: fast excitatory (AMPA), slow excitatory (NMDA), subtractive inhibitory (GABA_A), or shunting inhibitory (GABA_B).  User can connect different neurons (which are obtained with `get_neurons()`) to each other using `add_connection(pre_population, post_population, synapse_type)` method. Synapse type can be either `AMPA`, `NMDA`, `GABA_A` and `GABA_B`.\n",
    "\n",
    "\n",
    "Now, let's allocate a single neuron from the first core of Dynap-SE1, then define NMDA- and AMPA- type synaptic connections to our custom `input_spike_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOHDDgHBawHq"
   },
   "outputs": [],
   "source": [
    "DPI_neuron  = chip.get_neurons(1, 'Core_1') # Allocate single DPI neuron from Core 1\n",
    "DPI_NMDA_synapse = chip.add_connection(input_spike_generator, DPI_neuron, synapse_type='NMDA') # Define a slow excitatory synapse\n",
    "DPI_AMPA_synapse = chip.add_connection(input_spike_generator, DPI_neuron, synapse_type='AMPA') # Define a fast excitatory synapse\n",
    "\n",
    "# In Brian2 creating Synapses instance does not connect two endpoints, it only specifies synaptic dynamics \n",
    "# Let's connect two endpoints and set an initial weight of 300.\n",
    "\n",
    "chip.connect(DPI_NMDA_synapse, True)\n",
    "DPI_NMDA_synapse.weight = 300\n",
    "\n",
    "chip.connect(DPI_AMPA_synapse, True)\n",
    "DPI_AMPA_synapse.weight = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMNowT_fawHr"
   },
   "source": [
    "Until now, we created a spike generator, allocated a neuron from the chip, and formed two synaptic connections on the neuron (fast and slow, see the lecture material about synapses to understand the relation between neurotransmitters and fast/slow timescales). Before starting the simulation, we can add [monitors](https://brian2.readthedocs.io/en/stable/reference/brian2.monitors.html) \n",
    "for simulation variables that evolve during the simulation. This is one of the best parts of having a simulation of complex systems; we can monitor everything! This is not possible using a physical DYNAP-SE chip since only a few membrane potentials can be monitored via the analog ports at any particular time. What do we want to monitor?\n",
    "\n",
    "- Spikes from input spike generator\n",
    "- Output current of 1) fast excitatory 2) slow excitatory synapses \n",
    "- Neuron membrane current\n",
    "- Output activity of DPI neuron \n",
    "\n",
    "PS: If you are curious about where `I_syn_nmda`, `I_syn_ampa` and `Imem` variables come from, you should check `dynapse_eq.py` where we define DPI dynamics of neurons and synapses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GVC0fMyfawHr"
   },
   "outputs": [],
   "source": [
    "# Monitors\n",
    "mon_neuron_input  = SpikeMonitor(input_spike_generator, name='mon_neuron_input')\n",
    "mon_synapse_nmda  = StateMonitor(DPI_NMDA_synapse, 'I_syn_nmda', record=[0])\n",
    "mon_synapse_ampa  = StateMonitor(DPI_AMPA_synapse, 'I_syn_ampa', record=[0])\n",
    "mon_neuron_state  = StateMonitor(DPI_neuron, 'Imem', record=True)\n",
    "mon_neuron_output = SpikeMonitor(DPI_neuron, name='mon_neuron_output')\n",
    "\n",
    "# Add every instance we created to Brian network, so it will include them in the simulation\n",
    "network.add([input_spike_generator, DPI_neuron, DPI_NMDA_synapse, DPI_AMPA_synapse, mon_neuron_input, mon_synapse_nmda, mon_synapse_ampa, mon_neuron_output, mon_neuron_state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJJ_GaLmawHr"
   },
   "source": [
    "Now, let's run the simulation for a predefined time. Depending on your computer's CPU, it may take a while (1-10 minutes without a compiler and code vectorisation, and up to several seconds when a compiler is used). Note that a DYNAP-SE processor operates in real time, so 1000 ms of \"simulated time\" corresponds to 1 second of DYNAP-SE operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O19xjG58awHr"
   },
   "outputs": [],
   "source": [
    "# Simulation\n",
    "network.run(inp_duration * 1000 * ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYzJO-SXawHr"
   },
   "source": [
    "After the simulation is completed, we can see how the variables that we monitored evolved. Let's plot input spikes, membrane voltage, and output spikes to understand the neuron's response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYUP7y4cawHr"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10),dpi=200)\n",
    "plt.subplots_adjust(hspace=1)\n",
    "\n",
    "# Input Spikes \n",
    "plt.subplot(311)\n",
    "spike_placeholder = np.zeros(5000)\n",
    "spike_placeholder[np.array(mon_neuron_input.t/ms, dtype=int)]=1\n",
    "plt.plot(spike_placeholder,'k|')\n",
    "matplotlib.pyplot.yticks(range(1, 3))\n",
    "plt.ylim(0.5, 1.5)\n",
    "plt.title('Input Spikes')\n",
    "plt.ylabel('Neuron ID')\n",
    "#plt.xlabel('Time (ms)')\n",
    "\n",
    "plt.subplot(312)\n",
    "Imemvec = mon_neuron_state.Imem[0]\n",
    "plt.plot(mon_neuron_state.t/ms, Imemvec)\n",
    "\n",
    "plt.title('Neuron Membrane Current')\n",
    "plt.ylabel('Current (A)')\n",
    "#plt.xlabel('Time (ms)')\n",
    "\n",
    "plt.subplot(313)\n",
    "spike_placeholder = np.zeros(5000)\n",
    "spike_placeholder[np.array(mon_neuron_output.t/ms, dtype=int)]=2\n",
    "plt.plot(spike_placeholder,'k|')\n",
    "matplotlib.pyplot.yticks(range(1, 3))\n",
    "plt.ylim(1.5, 2.5)\n",
    "plt.title('Neuron Output Spikes')\n",
    "plt.ylabel('Neuron ID')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57LpJidpawHs"
   },
   "source": [
    "We provided an input spike train to a DPI neuron then observed some output spikes (If input spike parameters are correct). Now, we monitor the output current of DPI synapse that enters to neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HGgK6LJhawHs"
   },
   "outputs": [],
   "source": [
    "##################\n",
    "#  TODO: Play with tstart and tend to locate synaptic currents. Can you identify the spike condition behaviour in some of the plots generated? Try to estimate the time constant of the decay.\n",
    "#  Why do you think the amount of current at each input spike are not exactly same?\n",
    "#\n",
    "# Parameters\n",
    "tstart = 2000 # ms \n",
    "tend   = 2200 # ms\n",
    "##################\n",
    "\n",
    "# Plotting\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.set_size_inches(15, 8)\n",
    "fig.set_dpi(200)\n",
    "fig.suptitle('Synaptic Currents',y=1.02)\n",
    "s = int(1*ms / defaultclock.dt)\n",
    "\n",
    "ax1.plot(mon_neuron_state.t[tstart*s:tend*s]/ms, mon_synapse_ampa.I_syn_ampa[0][tstart*s:tend*s], linewidth=1.5)\n",
    "ax1.legend(['AMPA'])\n",
    "ax1.set_ylabel('Current (A)')\n",
    "ax1.set_xlabel('Time (ms)')\n",
    "ax1.grid(True)\n",
    "ax2.plot(mon_neuron_state.t[tstart*s:tend*s]/ms, mon_synapse_nmda.I_syn_nmda[0][tstart*s:tend*s], linewidth=1.5)\n",
    "ax2.legend(['NMDA'])\n",
    "ax2.set_ylabel('Current (A)')\n",
    "ax2.set_xlabel('Time (ms)')\n",
    "ax2.grid(True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6f4LVxumawHs"
   },
   "source": "Finally, we can observe the membrane current ($I_{mem}$) on silicon neuron and see how synaptic input accumulates and results in spikes."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sMldxeIXawHs"
   },
   "outputs": [],
   "source": [
    "##################\n",
    "#  TODO: Play with tstart and tend to observe membrane current fluctuations and the moments of spike output.\n",
    "#        Notice that the membrane current is more smoother than its synaptic input.\n",
    "#\n",
    "# Parameters\n",
    "tstart = 2000 # ms  \n",
    "tend   = 2200 # ms \n",
    "##################\n",
    "\n",
    "# Plotting\n",
    "s = int(1*ms / defaultclock.dt)\n",
    "plt.figure(figsize=(15,8),dpi=200)\n",
    "plt.plot(mon_neuron_state.t[tstart*s:tend*s]/ms, mon_neuron_state.Imem[0][tstart*s:tend*s], linewidth=1.5)\n",
    "plt.hlines(y=dynapse_param['Ispkthr']*1e-9/nA, xmin=tstart, xmax=tend, color='r', linestyles='-.')\n",
    "plt.legend(['$I_{mem}$', '$I_{thr}$'])\n",
    "plt.title('Neuron Membrane Current')\n",
    "plt.ylabel('Current (A)')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NestyvXAawHs"
   },
   "source": [
    "This is the end of Part 1.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Qc8W8K6awHs"
   },
   "source": [
    "# Part 2: Calculating the F-F curve of the AdEx neurons in DYNAP-SE\n",
    "\n",
    "In the second part, we will calculate the F-F curve of silicon neurons (similarly to the I-F curve that you calculated in Exercise 0). In neuroscience, the F-F curve is a function that relates to the input firing rate and the output firing rate of a neuron. Because the F-F curve only specifies the firing rate rather than exact spike times, it is a concept suited to the rate coding rather than the temporal coding model of neuronal computation. To obtain the F-F curve, we will simulate silicon neurons with a range of spike frequencies and observe the output behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRqO6gimawHs"
   },
   "source": [
    "There are multiple ways to create spike trains of different frequencies and stimulate neurons. One way is to stimulate single neuron with a fixed frequency and loop over a set of frequencies. Alternatively, we can stimulate multiple neurons, each with unique frequency in parallel. The latter is more compute-efficient on Brian2, and this is what we are going to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YNeNGa5yawHt"
   },
   "outputs": [],
   "source": [
    "## Calculating the F-F curve of DPI neurons\n",
    "##################\n",
    "# TODO: \n",
    "# - Play with frequency range and the simulation duration\n",
    "# \n",
    "# Parameters\n",
    "inp_duration   = 5     # second - Simulation duration (default: 5)\n",
    "freq_start     = 0     # Hz - Starting frequency (Neuron 0 will be stimulated with this Poisson rate) (default: 0)\n",
    "freq_stop      = 200   # Hz - Stop frequency (The last neuron will be stimulated with this Poisson rate) (default: 200)\n",
    "##################\n",
    "\n",
    "# Re-initialize the device\n",
    "device.reinit()\n",
    "device.activate()\n",
    "defaultclock.dt = 20 * us\n",
    "# Ignore Brian2 base warnings\n",
    "BrianLogger.suppress_name('base')\n",
    "\n",
    "# Create a Brian2 network and chip instance using that monitors Dynap-SE1 resources.\n",
    "network = Network()\n",
    "chip = DynapSE(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlnT135rawHt"
   },
   "source": [
    "To simulate neurons, we will use Poisson spikes. For stimulating $N$ neurons, we require $N$ different Poisson rates. To achieve that, we create a matrix with dimensions [simulation time steps, source ID], where the source ID represents the firing rate, e.g., source 5 will fire at 5 Hz, source 20 at 20 Hz, etc.\n",
    "\n",
    "Then we will create our network on Brian2, similar to Part 1, except for one single difference. This time, we will connect single sources to single corresponding neurons (one-to-one instead of all-to-all). To achieve that, we use `DPI_synapse.connect(j='i')`. As in Part 1 the execution time of the next cell depends on the compiler settings and computer and may take up to several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jkzbp0HpawHt"
   },
   "outputs": [],
   "source": [
    "# Create [time_steps, source ID] matrix, where firing rate is defined by source ID.\n",
    "# e.g., source 5 will fire at 5 Hz.\n",
    "rates2 = np.tile(np.linspace(freq_start, freq_stop, freq_stop-freq_start), (inp_duration*1000, 1)) # shape: (inp_duration*1000, 256)\n",
    "\n",
    "# Create a TimedArray according to rate information\n",
    "spike_timing = TimedArray(rates2 * Hz , dt=1 * us) \n",
    "\n",
    "# Using spike timing function, generate a Spike Generator that creates Poisson spikes\n",
    "input_spike_generator = PoissonGroup(freq_stop-freq_start, \"spike_timing(t,i)\")\n",
    "\n",
    "# Allocate neurons such that each firing frequency will be assigned to single neuron.\n",
    "DPI_neuron  = chip.get_neurons(freq_stop-freq_start, 'Core_1')\n",
    "DPI_synapse = chip.add_connection(input_spike_generator, DPI_neuron, synapse_type='NMDA')\n",
    "\n",
    "# One-to-one (j=i) mapping, instead of all-to-all connection\n",
    "chip.connect(DPI_synapse, j='i')\n",
    "DPI_synapse.weight = 300\n",
    "\n",
    "# Monitors\n",
    "mon_neuron_input  = SpikeMonitor(input_spike_generator, name='mon_neuron_input')\n",
    "mon_neuron_output = SpikeMonitor(DPI_neuron, name='mon_neuron_output')\n",
    "network.add([input_spike_generator, DPI_neuron, DPI_synapse, mon_neuron_input, mon_neuron_output])\n",
    "\n",
    "# Simulation\n",
    "network.run(inp_duration * 1000 * ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnArCxKPawHt"
   },
   "source": [
    "After the simulation, we can calculate each neuron's firing rate by looking at the number of spikes it generates throughout the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjp6xnutawHt"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,2.5),dpi=150)\n",
    "plt.subplot(121)\n",
    "plot(mon_neuron_output.count/ inp_duration * 1000 * ms,'-.') # Count number of spikes per neuron\n",
    "plt.xlabel('Input frequency (Hz)')\n",
    "plt.ylabel('Output frequency (Hz)')\n",
    "plt.title('DPI neuron')\n",
    "plt.grid(True)\n",
    "plt.subplot(122)\n",
    "plot(np.arange(-100,100,1),np.maximum(0,np.arange(-100,100,1)),'-.') # Implement ReLU function\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Output')\n",
    "plt.title('ReLU activation function')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htnYfU_AawHt"
   },
   "source": [
    "There are a few things to notice in the figure above. \n",
    "\n",
    "- Neurons did not fire until a certain input firing rate is reached. \n",
    "- The input/output spike-rate relation resembles the ReLU activation function of ANNs.\n",
    "- The F-F curve looks noisy. It is because of the stochastic nature of the Poisson inputs. The variance can be decreased by simulating the network over a longer time period.\n",
    "- When the output frequency is non-zero it looks linear, but we do not expect the firing rate to increase to arbitrary high output frequencies. The firing rate saturates at some point due to the refractory period etc.\n",
    "- Side note: In cortex, the firing rate of neurons also saturates under large input, but neurons almost always operate in the range of spike rates where the relation is linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBHIALrRawHt"
   },
   "outputs": [],
   "source": [
    "## Calculating the FF curve of DPI\n",
    "##################\n",
    "# TODO: \n",
    "# - Change the parameters to observe the saturation of FF-curve. (It may depend on various factors)\n",
    "#\n",
    "#\n",
    "##################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lF2RP6gDawHu"
   },
   "source": [
    "The slope of a neuron's F-F curve depends on many factors including the time constant of its input synapses and their synaptic efficacies. In the cell below, we compared F-F curves of DPI neurons with `AMPA` and `NMDA` synapses with three different weight strengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HInAk3KAawHu"
   },
   "outputs": [],
   "source": [
    "syn_type_list   = ['AMPA', 'NMDA']\n",
    "syn_weight_list = [300, 400, 500]\n",
    "\n",
    "spike_counts = np.zeros((6,200))\n",
    "for ix, synapse_type in enumerate(syn_type_list):\n",
    "    # Reinitialize the device\n",
    "    device.reinit()\n",
    "    device.activate()\n",
    "    defaultclock.dt = 20 * us\n",
    "\n",
    "    # Create a DynapSE instance\n",
    "    network = Network()\n",
    "    chip = DynapSE(network)\n",
    "\n",
    "    # New input generator\n",
    "    rates3 = np.tile(np.linspace(freq_start, freq_stop, freq_stop-freq_start), (5*1000, 1)) # shape: (inp_duration*1000, 256)\n",
    "    spike_timing = TimedArray(rates3 * Hz , dt=1 * us) \n",
    "    input_spike_generator = PoissonGroup(freq_stop-freq_start, \"spike_timing(t,i)\")\n",
    "    \n",
    "    # 200 neurons from Core 0\n",
    "    neurons_0  =  chip.get_neurons(freq_stop-freq_start, 'Core_0')\n",
    "    synapses_0 =  chip.add_connection(input_spike_generator, neurons_0, synapse_type=synapse_type)\n",
    "    chip.connect(synapses_0, j='i')\n",
    "    synapses_0.weight = syn_weight_list[0]\n",
    "    mon_neuron_output_0 = SpikeMonitor(neurons_0, name='mon_neuron_output_0')\n",
    "    \n",
    "    # 200 neurons from Core 1\n",
    "    neurons_1  =  chip.get_neurons(freq_stop-freq_start, 'Core_1')\n",
    "    synapses_1 =  chip.add_connection(input_spike_generator, neurons_1, synapse_type=synapse_type)\n",
    "    chip.connect(synapses_1, j='i')\n",
    "    synapses_1.weight = syn_weight_list[1]\n",
    "    mon_neuron_output_1 = SpikeMonitor(neurons_1, name='mon_neuron_output_1')\n",
    "    \n",
    "    # 200 neurons from Core 2\n",
    "    neurons_2  =  chip.get_neurons(freq_stop-freq_start, 'Core_2')\n",
    "    synapses_2 =  chip.add_connection(input_spike_generator, neurons_2, synapse_type=synapse_type)\n",
    "    chip.connect(synapses_2, j='i')\n",
    "    synapses_2.weight = syn_weight_list[2]\n",
    "    mon_neuron_output_2 = SpikeMonitor(neurons_2, name='mon_neuron_output_2')\n",
    "\n",
    "    # Monitors\n",
    "    network.add([input_spike_generator, neurons_0, neurons_1, neurons_2, synapses_0, synapses_1, synapses_2, mon_neuron_output_0, mon_neuron_output_1, mon_neuron_output_2])\n",
    "\n",
    "    # Simulation\n",
    "    network.run(inp_duration * 1000 * ms)\n",
    "    \n",
    "    # Save\n",
    "    spike_counts[3*ix+0,:] = mon_neuron_output_0.count/inp_duration\n",
    "    spike_counts[3*ix+1,:] = mon_neuron_output_1.count/inp_duration\n",
    "    spike_counts[3*ix+2,:] = mon_neuron_output_2.count/inp_duration\n",
    "    print('Reseting the chip settings ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qH-SATCeawHu"
   },
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(10,4), dpi=100)\n",
    "for i in range(2):\n",
    "    plt.subplot(120+i+1)\n",
    "    plt.title(f'DPI neuron with {syn_type_list[i]} synapse')\n",
    "    for j in range(3):\n",
    "        plt.plot(spike_counts[3*i+j], label=f'W: {syn_weight_list[j]}')\n",
    "        plt.xlabel('Input (Hz)')\n",
    "        plt.ylabel('Output (Hz)')\n",
    "        plt.ylim([0,50])\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2aX6cZRawHu"
   },
   "source": [
    "This is the end of Part 2.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0QyAaUtawHu"
   },
   "source": [
    "# Part 3: Spike-Frequency Adaptation of DPI Neurons\n",
    "\n",
    "Do you remember when a smell seems to be fading after you get used to it? Such mechanisms can be implemented with spike-frequency adaptation.\n",
    "\n",
    "In neuroscience, spike-frequency adaptation is defined as reducing a neuron's firing rate to a stimulus of constant intensity. Hence, when stimulated with a constant stimulus, many neurons initially respond with a high spike frequency that decays down to a lower steady-state frequency. There are several mechanisms by which neurons can adapt to new stimulus statistics; for example, neurons can change their time constants or other neurons suppress its firing rate via feedback inhibition. Usually, these adaptation processes are slower than the dynamics of action potential generation.\n",
    "\n",
    "As explained briefly in the Introduction of Part 1, silicon neurons on DynapSE are capable of spike-frequency adaptation. In the DYNAP-SE1 silicon neurons, the spike-frequency adaptation mechanism is implemented by an additional DPI filter that models the neuron's Calcium conductance, producing and after-hyper-polarizing (AHP) current $I_{ahp}$ which is proportional to the neuron's mean firing rate.\n",
    "\n",
    "There are two bias currents on the chip to tune the strength of the spike-frequency adaptation (see the figure of the DPI circuit at the top and related differential equation approximation):\n",
    "\n",
    "- $I_{tauahp}$ : Leakage current for spike-frequency adaptation (how fast the adaptation is)\n",
    "- $I_{thahp}$  : Threshold for spike-frequency adaptation (strength of the adaptation)\n",
    "\n",
    "Adaptation will then follow from the physics of the silicon and DPI circuit.\n",
    "\n",
    "In Part 1 and Part 2, we created various spike trains, allocated neurons, and created synapses on the Dynap-SE1 simulator. In Part 3, we will learn another fundamental block of our neuromorphic chips, called Bias Generator (BiasGen).\n",
    "\n",
    "BiasGen is a configurable current generator that biases the gate voltage of specific transistors on the chip to generate the desired currents. By BiasGen, the user can adjust neuron and synapse parameters and thus resembles \"hyperparameters\" of ANN. In research, we spend a notable amount of time tuning network parameters via BiasGen so that the network operates in a specific regime that we choose.  You can check the original paper of BiasGen [here](https://ieeexplore.ieee.org/document/5537475). The current version of BiasGen inside the Dynap-SE1 is much more advanced. For example, it can compensate the temperature dependency of generated currents. Despite this compensation, neuromorphic chips operating in the analog regime can be sensitive to temperature variations, see for example Figure 6 in this [paper](https://doi.org/10.3389/fnins.2020.00150), which is based on experiments with a DYNAP-SE1.\n",
    "\n",
    "In the following you will create a regular spiking pattern and tune two biases, `Itauahp` and `Ithahp,` for observing a spike-frequency adaptation. With correct values, you should see the firing rate adapting to the constant stimulus after some time. \n",
    "\n",
    "To control BiasGen, you will use the `set_bias(dict, 'core_ID')` method, which takes a dictionary of address, current pairs, and the Core ID. Core ID is required because the biases are shared within a single core of DynapSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ml96guJWawHu"
   },
   "outputs": [],
   "source": [
    "## Observing Adaptation Effect\n",
    "##################\n",
    "# TODO:\n",
    "# - Play with Itauahp and Ithahp currents to observe a spike-frequency adaptation\n",
    "#\n",
    "#\n",
    "# Parameters\n",
    "pulse_start  = 1     # second - Start timing of pulse\n",
    "pulse_stop   = 4     # second - Stop timing of pulse\n",
    "inp_duration = 5     # second - Simulation duration\n",
    "firing_rate  = 150   # Hz - Firing rate of the source\n",
    "\n",
    "adaptation_conf = {\"Itauahp\": 0.04 * pA,  # Adaptation time constant (Default: 0.04 pA, 0.05 pA)             \n",
    "                   \"Ithahp\" : 0.05 * pA}  # Adaptation gain\n",
    "\n",
    "\n",
    "ampa_conf       = {\"I_tau_syn_ampa\": 10 * pA, # AMPA synapse time-constant (Default: 10 pA, 10pA)\n",
    "                   \"I_g_syn_ampa\"  : 10 * pA} # AMPA synapse gain\n",
    "\n",
    "##################\n",
    "\n",
    "# Reinitialize the device\n",
    "#set_device('cpp_standalone', build_on_run=True) # Requires a compiler\n",
    "device.reinit()\n",
    "device.activate()\n",
    "defaultclock.dt = 20 * us\n",
    "# Ignore Brian2 base warnings\n",
    "BrianLogger.suppress_name('base')\n",
    "\n",
    "# Create a regular spiking pattern (taken from Part 1.)\n",
    "spikes = np.zeros(inp_duration*1000)\n",
    "dt = int(1000/firing_rate)\n",
    "spikes[pulse_start*1000:pulse_stop*1000:dt] = 1.0\n",
    "spike_timing = np.where(spikes==1)[0] * ms\n",
    "neuron_indices = np.zeros(len(spike_timing))\n",
    "input_spike_generator = SpikeGeneratorGroup(1, indices=neuron_indices, times=spike_timing, name='InpSpikeGenerator')    \n",
    "\n",
    "# Create a Brian2 network and chip instance using that monitors DynapSE resources.\n",
    "network = Network()\n",
    "chip = DynapSE(network)\n",
    "\n",
    "# Connect a single spike generator to a single DPI neuron \n",
    "DPI_neuron  = chip.get_neurons(1, 'Core_1')\n",
    "DPI_synapse = chip.add_connection(input_spike_generator, DPI_neuron, synapse_type='AMPA')\n",
    "chip.connect(DPI_synapse, True)\n",
    "DPI_synapse.weight = 500\n",
    "\n",
    "\n",
    "# Using BiasGen, set adaptation configurations for Core #1\n",
    "# In DynapSE, biases are set per Core.\n",
    "# In CTXCTL, this command is : set_bias(chip_id, bias_id, fine_value, coarse_value, t_type)\n",
    "chip.set_bias(adaptation_conf, 'Core_1')\n",
    "chip.set_bias(ampa_conf, 'Core_1')\n",
    "\n",
    "\n",
    "# Monitors\n",
    "mon_neuron_input  = SpikeMonitor(input_spike_generator, name='mon_neuron_input')\n",
    "mon_neuron_output = SpikeMonitor(DPI_neuron, name='mon_neuron_output')\n",
    "mon_adapt_state  = StateMonitor(DPI_neuron,  'Iahp', record=True)\n",
    "mon_mem_state  = StateMonitor(DPI_neuron,  'Imem', record=True)\n",
    "network.add([input_spike_generator, DPI_neuron, DPI_synapse, mon_neuron_input, mon_neuron_output,mon_adapt_state,mon_mem_state])\n",
    "\n",
    "# Simulation\n",
    "network.run(inp_duration * 1000 * ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_EoUQwWawHu"
   },
   "source": [
    "Now, you will monitor the input-output spikes, membrane current, and the adaptation current. If you set up the spike-adaptation currents correctly, you will see that the neuron firing rate will decrease in the presence of a constant input rate. However, be aware that tuning the spike-frequency is a bit tricky, and its effect is clearly visible only in a small range of parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8v4903OBawHv"
   },
   "outputs": [],
   "source": [
    "##################\n",
    "#  TODO: \n",
    "# - Find the time window to observe spike-frequency adaptation.\n",
    "#\n",
    "# Parameters\n",
    "tstart = 950 # ms - \n",
    "tend   = 1500 # ms -\n",
    "##################\n",
    "\n",
    "# Plotting\n",
    "spike_placeholder = np.zeros(inp_duration*1000)\n",
    "spike_placeholder[np.array(mon_neuron_input.t/ms, dtype=int)]=2\n",
    "\n",
    "spike_placeholder2 = np.zeros(inp_duration*1000)\n",
    "spike_placeholder2[np.array(mon_neuron_output.t/ms, dtype=int)]=3\n",
    "\n",
    "s = int(1*ms / defaultclock.dt)\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "fig.set_size_inches(7,4)\n",
    "fig.set_dpi(150)\n",
    "ax1.set_xlabel('Time (ms)')\n",
    "ax1.plot(spike_placeholder,'k.')\n",
    "plt.yticks(np.arange(1, 5), ['a','Input Spikes','Output Spikes','d'])\n",
    "ax1.tick_params(axis='y')\n",
    "plt.ylim(1.5, 3.5)\n",
    "plt.xlim(tstart,tend)\n",
    "ax2 = ax1.twinx()  \n",
    "ax1.plot(spike_placeholder2,'k.')\n",
    "\n",
    "ax2.set_ylabel('Adaptation Current (A)', color='r')  \n",
    "ax2.plot(mon_adapt_state.t/ms, mon_adapt_state.Iahp[0], linewidth=1.5,color='r')\n",
    "ax2.tick_params(axis='y', labelcolor='r')\n",
    "plt.xlim(tstart,tend)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.grid(True)\n",
    "\n",
    "ax2.plot(mon_mem_state.t/ms, mon_mem_state.Imem[0], linewidth=1.5, color='g')\n",
    "plt.legend(['$I_{ahp}$','$I_{mem}$','c'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeziZGbgawHv"
   },
   "source": [
    "You can plot the inter-spike interval (ISI) of the output spikes to more clearly visualize the effect. The ISI is the time between two subsequent spikes, which can be computed with the NumPy diff() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJMH64UZawHv"
   },
   "outputs": [],
   "source": [
    "# Plotting output ISI\n",
    "plt.figure(figsize=(10,4),dpi=100)\n",
    "plot(np.diff(mon_neuron_output.t/ms),'o')\n",
    "plt.ylabel('Output ISI (ms)')\n",
    "plt.xlabel('Incoming spike count')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BghOsOCtawHv"
   },
   "source": [
    "Congratulations! This is the end of the exercise.\n",
    "\n",
    "You should now show your solutions to one of the teachers during a scheduled lab session, either physically in the computer lab on campus or remotely in Zoom. Instructions for how to sign up for showing your solution is available in Canvas."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NICE2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
